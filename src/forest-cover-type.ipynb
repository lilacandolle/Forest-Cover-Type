{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest Cover Type Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load dataset\n",
    "X, y = fetch_covtype(return_X_y=True)\n",
    "\n",
    "# create dataframe\n",
    "feature_names = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', \n",
    "                 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1', 'Wilderness_Area2', \n",
    "                'Wilderness_Area3', 'Wilderness_Area4', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7',\n",
    "                'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16', \n",
    "                 'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24', 'Soil_Type25', \n",
    "                 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34', \n",
    "                 'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']\n",
    "\n",
    "# Making a DataFrame\n",
    "covtype_df = pd.DataFrame(X, columns=feature_names)\n",
    "covtype_df['Cover_Type'] = y\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the code for Project 2 (Marco Pozzoli, Lila Cassan) and the code of the course Applied Analysis and Machine Learning by Morten Hjorth-Jensen https://github.com/CompPhysics/MachineLearning/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define RELU function as the activation function for the hidden layer\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "#define softmax as the activation function for the output layer\n",
    "def softmax(a):\n",
    "    expA = np.exp(a)\n",
    "    return expA / expA.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization of weight and biases for a flexible number of hidden layers including the output layer\n",
    "def initialize_parameters(layer_dims):\n",
    "    parameters = {}\n",
    "    for i in range(1, len(layer_dims)):\n",
    "        parameters[f'W{i}'] = np.random.randn(layer_dims[i-1], layer_dims[i]) * 0.01\n",
    "        parameters[f'b{i}'] = np.zeros((layer_dims[i], 1))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now write the feed forward pass\n",
    "def feed_forward(X, parameters):\n",
    "    cache = {'A0': X}\n",
    "    for i in range(1, len(parameters)//2 + 1):\n",
    "        Z = cache[f'A{i-1}'] @ parameters[f'W{i}'] + parameters[f'b{i}'].T\n",
    "        A = relu(Z) if i < len(parameters)//2 else softmax(Z) #if we are at the output layer, we use softmax\n",
    "        cache[f'Z{i}'] = Z\n",
    "        cache[f'A{i}'] = A\n",
    "    return cache\n",
    "\n",
    "def feed_forward_hidden(X, parameters):\n",
    "    cache = {'A0': X}\n",
    "    for i in range(1, len(parameters)//2):  # s'arrête avant la couche de sortie\n",
    "        Z = cache[f'A{i-1}'] @ parameters[f'W{i}'] + parameters[f'b{i}']\n",
    "        A = relu(Z)\n",
    "        cache[f'Z{i}'] = Z\n",
    "        cache[f'A{i}'] = A\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we now define the cost/loss function. We use the cross-entropy because it is a classification problem\n",
    "def cross_entropy(prediction, target):\n",
    "    epsilon = 1e-12 #added to avoid log(0)\n",
    "    return -(target*np.log(prediction+epsilon) + (1-target)*np.log(1-prediction+epsilon))\n",
    "\n",
    "def d_cross_entropy(prediction, target):   #attention: retrouver dérivée\n",
    "    epsilon = 1e-12 #added to avoid log(0)\n",
    "    return -(target/(prediction+epsilon) - (1-target)/(1-prediction+epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(X, Y, cache, parameters):\n",
    "    m = Y.shape[0]\n",
    "    gradients = {}\n",
    "    output_error = d_cross_entropy(cache[f'A{len(parameters)//2}'], transformation(Y))\n",
    "    for i in range(len(parameters)//2, 0, -1):\n",
    "        gradients[f'dW{i}'] = 1/m * cache[f'A{i-1}'].T@ output_error\n",
    "        gradients[f'db{i}'] = 1/m * np.sum(output_error, axis=0, keepdims=True)\n",
    "        output_error = np.dot(output_error, parameters[f'W{i}'].T) * (cache[f'Z{i-1}'] > 0) if i > 1 else None\n",
    "    return gradients\n",
    "\n",
    "def backpropagation_update_parameters(parameters, gradients, learning_rate):\n",
    "    for i in range(1, len(parameters)//2 + 1):\n",
    "        parameters[f'W{i}'] -= learning_rate * gradients[f'dW{i}']\n",
    "        parameters[f'b{i}'] -= learning_rate * gradients[f'db{i}'].T\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformation\n",
    "def transformation(z, num_classes = 7):\n",
    "    z = np.eye(num_classes)[z-1] #because classes are from 1 to 8 and not from 0 to 7\n",
    "    return z\n",
    "\n",
    "#transformation inverse\n",
    "def inverse_transformation(z):\n",
    "    z = np.argmax(z, axis = 1)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at iteration 0 0.4020933762595657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_t/pzbtlqfs06q4gkr88b12hv9r0000gn/T/ipykernel_1373/315493064.py:7: RuntimeWarning: overflow encountered in exp\n",
      "  expA = np.exp(a)\n",
      "/var/folders/_t/pzbtlqfs06q4gkr88b12hv9r0000gn/T/ipykernel_1373/315493064.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "  return expA / expA.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at iteration 100 nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/lila.cassan/Desktop/Cours/Cours_Oslo/FYS-STK4155/Forest-Cover-Type/src/forest-cover-type.ipynb Cellule 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lila.cassan/Desktop/Cours/Cours_Oslo/FYS-STK4155/Forest-Cover-Type/src/forest-cover-type.ipynb#X21sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m#training\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lila.cassan/Desktop/Cours/Cours_Oslo/FYS-STK4155/Forest-Cover-Type/src/forest-cover-type.ipynb#X21sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lila.cassan/Desktop/Cours/Cours_Oslo/FYS-STK4155/Forest-Cover-Type/src/forest-cover-type.ipynb#X21sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     cache \u001b[39m=\u001b[39m feed_forward(X_train, parameters)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lila.cassan/Desktop/Cours/Cours_Oslo/FYS-STK4155/Forest-Cover-Type/src/forest-cover-type.ipynb#X21sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     gradients \u001b[39m=\u001b[39m backpropagation(X_train, y_train, cache, parameters)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lila.cassan/Desktop/Cours/Cours_Oslo/FYS-STK4155/Forest-Cover-Type/src/forest-cover-type.ipynb#X21sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     parameters \u001b[39m=\u001b[39m backpropagation_update_parameters(parameters, gradients, learning_rate)\n",
      "\u001b[1;32m/Users/lila.cassan/Desktop/Cours/Cours_Oslo/FYS-STK4155/Forest-Cover-Type/src/forest-cover-type.ipynb Cellule 12\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lila.cassan/Desktop/Cours/Cours_Oslo/FYS-STK4155/Forest-Cover-Type/src/forest-cover-type.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m cache \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mA0\u001b[39m\u001b[39m'\u001b[39m: X}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lila.cassan/Desktop/Cours/Cours_Oslo/FYS-STK4155/Forest-Cover-Type/src/forest-cover-type.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(parameters)\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lila.cassan/Desktop/Cours/Cours_Oslo/FYS-STK4155/Forest-Cover-Type/src/forest-cover-type.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     Z \u001b[39m=\u001b[39m cache[\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mA\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m] \u001b[39m@\u001b[39;49m parameters[\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mW\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m] \u001b[39m+\u001b[39;49m parameters[\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mb\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mT\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lila.cassan/Desktop/Cours/Cours_Oslo/FYS-STK4155/Forest-Cover-Type/src/forest-cover-type.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     A \u001b[39m=\u001b[39m relu(Z) \u001b[39mif\u001b[39;00m i \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(parameters)\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m softmax(Z) \u001b[39m#if we are at the output layer, we use softmax\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lila.cassan/Desktop/Cours/Cours_Oslo/FYS-STK4155/Forest-Cover-Type/src/forest-cover-type.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     cache[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mZ\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m Z\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#inizializzo dimensioni layers\n",
    "n_inputs, n_features = X_train.shape\n",
    "hid = 7 #number of neurons in the hidden layers\n",
    "out = 7 #number of neurons in the output layer\n",
    "layer_dims = [n_features, hid, out] #for one hidden layer\n",
    "#layer_dims = [n_features, hid, hid, out] for two hidden layers\n",
    "\n",
    "#inizializzo parametri\n",
    "parameters = initialize_parameters(layer_dims)\n",
    "\n",
    "#initialization of hyperparameters\n",
    "learning_rate = 1e-4\n",
    "epochs = 10000\n",
    "\n",
    "#training\n",
    "for i in range(epochs):\n",
    "    cache = feed_forward(X_train, parameters)\n",
    "    gradients = backpropagation(X_train, y_train, cache, parameters)\n",
    "    parameters = backpropagation_update_parameters(parameters, gradients, learning_rate)\n",
    "    if i % 100 == 0:\n",
    "        print(f'Cost at iteration {i}', cross_entropy(cache[f'A{len(parameters)//2}'], transformation(y_train)).mean())\n",
    "\n",
    "#testing\n",
    "cache = feed_forward(X_test, parameters)\n",
    "predictions = cache[f'A{len(parameters)//2}']\n",
    "predictions = np.round(predictions)\n",
    "accuracy = accuracy_score(y_test, inverse_transformation(predictions))\n",
    "print('Accuracy on test set:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
